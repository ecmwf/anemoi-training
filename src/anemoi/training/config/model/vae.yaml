activation: GELU
num_channels: 256
no_latent_levels: 1 # Hierarchical VAE setting
no_z_samples: 1 # No of Z samples

lightning_module_type:
  _target_: aifs.train.autoencoder.GraphReconstructor


processor:
  _target_: aifs.layers.processor.TransformerProcessor
  _convert_: all
  activation: ${model.activation}
  num_layers: 4
  num_chunks: 2
  mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
  num_heads: 16 # GraphTransformer or Transformer only
  window_size: 256
  dropout_p: 0.01


encoder:
  _target_: aifs.layers.mapper.GraphTransformerForwardMapper
  _convert_: all
  trainable_size: ${model.trainable_parameters.data2hidden}
  activation: ${model.activation}
  num_chunks: 1
  mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
  num_heads: 16 # GraphTransformer or Transformer only

decoder:
  _target_: aifs.layers.mapper.GraphTransformerBackwardMapper
  _convert_: all
  trainable_size: ${model.trainable_parameters.hidden2data}
  activation: ${model.activation}
  num_chunks: 1
  mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
  num_heads: 16 # GraphTransformer or Transformer only

trainable_parameters:
  data: 8
  hidden: 8
  data2hidden: 8
  hidden2data: 8
