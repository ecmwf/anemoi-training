# this is the CERRA config for anemoi-training with the stretched grid
defaults:
 - data: zarr
 - dataloader: native_grid
 - diagnostics: evaluation
 - hardware: slurm
 - graph: stretched_grid
 - model: graphtransformer
 - training: default
 - _self_
 
diagnostics:
  log:
    mlflow:
      enabled: True
      offline: False
      authentication: True
      experiment_name: 'aifs-stretch-cerra'
      log_model: False
      tracking_uri: 'https://mlflow.ecmwf.int'
    wandb:
      enabled: False
  plot:
    enabled: False
#    learned_features: False
    parameters:
      # - z_500
      - t_850
      - u_850
      - v_850
      - 2t
      - sp
      - msl
    parameters_histogram: []
      # - z_500
      # - 2t
    parameters_spectrum: []
  print_memory_summary: True
#  show_entire_globe: False

dataloader:
  num_workers:
    training: 2
    validation: 2
    test: 2
    predict: 2
  batch_size:
    training: 1
    validation: 1
    test: 1
    predict: 1

  dataset:
    cutout:
      - dataset: ${hardware.paths.data}/experimental/${hardware.files.dataset_lam}
      - dataset: ${hardware.paths.data}/stable/${hardware.files.dataset}
    adjust: all

  training:
    start: "1984-09-02"
    end: "2005-12-31"
  validation:
    start: "2006-01-01"
    end: "2007-12-31"
  test:
    start: "2008-01-01"
    end: "2008-06-29"

  limit_batches:
    training: 10
    validation: 10

hardware:
  num_gpus_per_model: 4
  paths:
    data: /home/mlx/ai-ml/datasets/
    grids: /home/mlx/ai-ml/grids/
    output: ${oc.env:HPCPERM}/anemoi/
    checkpoints: ${oc.env:SCRATCH}/anemoi/checkpoint/
    graph: ${oc.env:HPCPERM}/anemoi/graphs/
  files:
    dataset: aifs-ea-an-oper-0001-mars-o96-1979-2022-6h-v6.zarr
    dataset_lam: cerra-rr-an-oper-0001-mars-5p5km-1984-2008-6h-v1-smhi.zarr
    graph: test-anemoi-training_CERRA.pt
    warm_start: null #specific checkpoint to start from, defaults to last.ckpt

data:
  resolution: 5p5km
  forcing:
  - "cos_latitude"
  - "cos_longitude"
  - "sin_latitude"
  - "sin_longitude"
  - "cos_julian_day"
  - "cos_local_time"
  - "sin_julian_day"
  - "sin_local_time"
  - "insolation"
  - "lsm"
  diagnostic:
  - tp
  normalizer:
    default: "mean-std"
    std:
    - "tp"
    min-max:
    max:
    none:
    - "cos_latitude"
    - "cos_longitude"
    - "sin_latitude"
    - "sin_longitude"
    - "cos_julian_day"
    - "cos_local_time"
    - "sin_julian_day"
    - "sin_local_time"
    - "insolation"
    - "lsm"

model:
  num_channels: 512
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0 # GNN and GraphTransformer Processor only

graph:
  save_graph_plots: True
  nodes:
    hidden:
      node_builder:
        lam_resolution: 9

training:
  run_id: '' #path to store the experiment in with output_base as root, null for random name, =fork_run_id to continue training in the same folder.
  fork_run_id: null #path to the experiment to fork from with output_base as root
  load_weights_only: False #loads entire model if False, loads only weights if True
  lr:
    rate: 5e-4  #8 * 0.625e-4
    min: 2.4e-6 #8 * 3e-7
    iterations: 150000
  
  validation_metrics:
    # loss class to initialise
    - _target_: anemoi.training.losses.mse.WeightedMSELoss
      #Â Scalars to include in loss calculation
      # Available scalars include, 'variable'
      scalars: []
      # other kwargs
      ignore_nans: True
    - _target_: anemoi.training.losses.limitedarea.WeightedMSELossLimitedArea
      scalars: ['limited_area_mask']
      inside_lam: True
      wmse_contribution: False
      ignore_nans: True
