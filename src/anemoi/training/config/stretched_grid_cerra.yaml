defaults:
 - data: zarr
 - dataloader: native_grid
 - diagnostics: eval_rollout
 - hardware: slurm
 - graph: stretched_grid
 - model: graphtransformer
 - training: default
 - _self_
 
diagnostics:
  log:
    mlflow:
      enabled: True
      offline: False
      authentication: True
      experiment_name: 'aifs-stretch-cerra'
      log_model: False
      tracking_uri: 'https://mlflow.ecmwf.int'
    wandb:
      enabled: False
  plot:
    enabled: False
#    learned_features: False
    parameters:
      # - z_500
      - t_850
      - u_850
      - v_850
      - 2t
      - sp
      - msl
    parameters_histogram: []
      # - z_500
      # - 2t
    parameters_spectrum: []
  print_memory_summary: True
#  show_entire_globe: False

dataloader:
  num_workers:
    training: 2
    validation: 2
    test: 2
    predict: 2
  batch_size:
    training: 1
    validation: 1
    test: 1
    predict: 1

  dataset:
    cutout:
      - dataset: ${hardware.paths.data}/experimental/${hardware.files.dataset_lam}
      - dataset: ${hardware.paths.data}/stable/${hardware.files.dataset}
    adjust: all

  training:
    start: "1984-09-02"
    end: "2005-12-31"
    statistics: ${hardware.paths.data}/stable/${hardware.files.dataset}
  validation:
    start: "2006-01-01"
    end: "2007-12-31"
    statistics: ${hardware.paths.data}/stable/${hardware.files.dataset}
  test:
    start: "2008-01-01"
    end: "2008-06-29"
    statistics: ${hardware.paths.data}/stable/${hardware.files.dataset}

  limit_batches:
    training: 100
    validation: 100

hardware:
  num_gpus_per_model: 4
  paths:
    data: /home/mlx/ai-ml/datasets/
    grids: /home/mlx/ai-ml/grids/
    output: ${oc.env:HPCPERM}/anemoi/
    checkpoints: ${oc.env:SCRATCH}/anemoi/checkpoint/
    graph: ${oc.env:HPCPERM}/anemoi/graphs/
  files:
    dataset: aifs-ea-an-oper-0001-mars-o96-1979-2022-6h-v6.zarr
    dataset_lam: cerra-rr-an-oper-0001-mars-5p5km-1984-2008-6h-v1-smhi.zarr
    graph: test-anemoi-training_CERRA.pt
    warm_start: null #specific checkpoint to start from, defaults to last.ckpt

data:
  resolution: 5p5km

model:
  num_channels: 512
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0 # GNN and GraphTransformer Processor only

graph:
  save_graph_plots: True
  nodes:
    hidden:
      node_builder:
        lam_resolution: 9

training:
  run_id: '' #path to store the experiment in with output_base as root, null for random name, =fork_run_id to continue training in the same folder.
  fork_run_id: null #path to the experiment to fork from with output_base as root
  load_weights_only: False #loads entire model if False, loads only weights if True
  lr:
    rate: 5e-4  #8 * 0.625e-4
    min: 2.4e-6 #8 * 3e-7
    iterations: 150000
